<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Indraja</title>
<meta name="description" content="">
<meta name="author" content="">

<!-- Favicons
    ================================================== -->
<link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon">
<link rel="apple-touch-icon" href="img/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="72x72" href="img/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="114x114" href="img/apple-touch-icon-114x114.png">

<!-- Bootstrap -->
<link rel="stylesheet" type="text/css"  href="css/bootstrap.css">
<link rel="stylesheet" type="text/css" href="fonts/font-awesome/css/font-awesome.css">

<!-- Stylesheet
    ================================================== -->
<link rel="stylesheet" type="text/css"  href="css/style.css">
<link rel="stylesheet" type="text/css" href="css/nivo-lightbox/nivo-lightbox.css">
<link rel="stylesheet" type="text/css" href="css/nivo-lightbox/default.css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700,800,600,300' rel='stylesheet' type='text/css'>
<script type="text/javascript" src="js/modernizr.custom.js"></script>
</head>
<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
<!-- Navigation
    ==========================================-->
<nav id="menu" class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button>
      <a class="navbar-brand page-scroll" href="#page-top"><i class="fa fa-play fa-rotate-270"></i> Indraja</a> </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav navbar-right">
        <li><a href="#page-top" class="page-scroll">Home</a></li>
        <li><a href="#about" class="page-scroll">About</a></li>
        <li><a href="#portfolio" class="page-scroll">Portfolio</a></li>
        <li><a href="#contact" class="page-scroll">Get In Touch</a></li>
      </ul>
    </div>
    <!-- /.navbar-collapse -->
  </div>
  <!-- /.container-fluid -->
</nav>
<!-- Header -->
<header id="header">
  <div class="intro">
    <div class="container">
      <div class="row">
        <div class="intro-text">
          <h1>Indraja Bandla</h1>
          <p>Data Science • Python • SQL</p>
          <a href="#about" class="btn btn-custom btn-lg page-scroll">Learn More</a> </div>
      </div>
    </div>
  </div>
</header>
<!-- About Section -->
<div id="about">
  <div class="container">
    <div class="section-title text-center center">
      <h2>Hello I am..</h2>
      <hr class="about-hr">
    </div>
    <div class="row about-me text-center center">
      <img src="img/indraja.jpeg" class="img-responsive my-image" alt="">
      <div class="about-text">
        <p>a Junior Data Scientist with over three years of experience in Analysis, Design and Development. I always welcome opportunities where I get the scope to work on challenging assignments.</p>
        <p>I played multiple roles and built a strong background in database development and data analysis. After working as an Oracle Applications Developer, I have developed a keen interest in turning large chunks of data into stories and insights for finance and telecom clients. One of my greatest assets is my zeal towards exploring new technologies. I am always on the lookout for machine learning techniques that makes my work far more engaging.</p>
        <p>To further improve my skill set, I joined General Assembly to upskill and figure out much more in Data Analytics and Data Science.General Assembly's Data Science Immersive (DSI) is a 12-week long intensive boot camp dedicated to analyse and develop using Machine learning techniques in Python.I explored EDA, Feature Engineering, Supervised and Unsupervised learning, Optimisation techniques, Statistical inference, data visualisation using Python and Tableau.I am skilled in SQL, Pl/SQL, Unix shell scripting, Microsoft office and core java. </p>
        <p>Being an ambitious person, I am driven to continue to build my career as Data Scientist where I can build data narratives and handle data using different tools and Methodologies.</p>
      </div>
      <div>
        <a href="#portfolio" class="btn btn-default btn-lg page-scroll">My Portfolio</a>
      </div>
    </div>
  </div>
</div>
<!-- Portfolio Section -->
<div id="portfolio">
  <div class="container">
    <div class="section-title text-center center">
      <h2>Portfolio</h2>
      <hr>
    </div>
    <div class="categories">
      <ul class="cat">
        <li>
          <ol class="type">
            <li><a href="#" data-filter="*" class="active">All</a></li>
            <li><a href="#" data-filter=".assignment">Assignments</a></li>
            <li><a href="#" data-filter=".capstone">Capstone Project</a></li>
          </ol>
        </li>
      </ul>
      <div class="clearfix"></div>
    </div>
    <div class="portfolio-items is-flex">
      <div class="capstone">
        <div class="portfolio-item">
          <img src="img/portfolio/crmap.jpg" class="portfolio-img img-responsive" alt="Project Title">
          <p>Credit Risk Analysis using Tableau and Machine Learning Techniques in Python</p>
          <button class="btn btn-default" data-toggle="modal" data-target="#capstone">Read More...</button>
        </div>
      </div>
      <div class="assignment">
        <div class="portfolio-item">
          <img src="img/portfolio/keyword.png" class="portfolio-img img-responsive" alt="Project Title">
          <p>Analysed and visualised by Web scraping the job sites.</p>
          <button class="btn btn-default" data-toggle="modal" data-target="#webscrape">Read More...</button>
        </div>
      </div>
      <div class="assignment">
        <div class="portfolio-item">
          <img src="img/portfolio/homesale.jpg" class="portfolio-img img-responsive" alt="Project Title">
          <button class="btn btn-default" data-toggle="modal" data-target="#predictive">Read More...</button>
        </div>
       </div>
      <div class="assignment">
        <div class="portfolio-item">
          <img src="img/portfolio/evergreen2.png" class="portfolio-img img-responsive" alt="Project Title">
          <p>Finding evergreen sites using JSON</p>
          <button class="btn btn-default" data-toggle="modal" data-target="#greenness">Read More...</button>
        </div>
      </div>
      <div class="assignment">
        <div class="portfolio-item">
          <img src="img/portfolio/music2.jpg" class="portfolio-img img-responsive" alt="Project Title">
          <p>Music Blogging- What makes a song hit? </p>
          <button class="btn btn-default" data-toggle="modal" data-target="#music">Read More...</button>
        </div>
      </div>
      <div class="assignment">
        <div class="portfolio-item">
          <img src="img/portfolio/sale.jpg" class="portfolio-img img-responsive" alt="Project Title">
          <p>Trend Analysis using time series</p>
          <button class="btn btn-default" data-toggle="modal" data-target="#walmart">Read More...</button>
        </div>
      </div>
      <div class="assignment">
        <div class="portfolio-item">
          <img src="img/portfolio/churn2.png" class="portfolio-img img-responsive" alt="Project Title">
          <p>KNN classification and imputations: cellphone churn data </p>
          <button class="btn btn-default" data-toggle="modal" data-target="#churn">Read More...</button>
        </div>
      </div>
      <div class="assignment">
        <div class="portfolio-item">
          <img src="img/portfolio/sentiment.jpg" class="portfolio-img img-responsive" alt="Project Title">
          <p>NLP Sentiment Analysis</p>
          <button class="btn btn-default" data-toggle="modal" data-target="#sentiment">Read More...</button>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- Contact Section -->
<div id="contact" class="text-center">
  <div class="container">
    <div class="center">
      <h2>Get In Touch</h2>
      <hr>
    </div>
    <div class="col-md-8 col-md-offset-2">
      <div class="social">
        <ul>
          <li><a target="_blank" href="https://www.linkedin.com/in/indraja-bandla/"><i class="fa fa-linkedin"></i></a></li>
          <li><a target="_blank" href="https://github.com/Indu4191/Projects"><i class="fa fa-github"></i></a></li>
          <li><a target="_blank" href="https://indu4191.blogspot.com.au/"><i class="fa fa-user"></i></a></li>
        </ul>
      </div>
    </div>
  </div>
</div>
<div id="capstone" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Overview</h4>
      </div>
      <div class="modal-body">
        <p>The goal of this project is multi-pronged, to build a model that borrowers can use to help make the best financial
           decisions, and for the lenders to foresee when a borrower might lead into financial distress. The intent is to
           improve the state of the art  in credit scoring by predicting probability of credit risk. I got the dataset from
           Kaggle with 1000 instances.In order to perform analysis , 20 attributes like his economic status, credit history ,
           personal status etc are considered. Once Exploratory Analysis is done , Data Visualisation is performed using tableau and
<<<<<<< HEAD
           Python (matplotlib, seaborn).You can view my Tableau dashboard here
           <a>https://public.tableau.com/profile/indraja.bandla#!/vizhome/CRMgermandatavisualtreat/Story1</a>
=======
           Python (matplotlib, seaborn).You can
           <a target="_blank" href="https://public.tableau.com/profile/indraja.bandla#!/vizhome/CRMgermandatavisualtreat/Story1">view my Tableau dashboard.</a>
>>>>>>> 82e66c4ce0410474de3db80ccd4a544aa9f49a14
        </p>
        <p>I tried Logistic,Ridge and Lasso to eliminate the unimportant features. Ridge did not helped much but Lasso helped to pick 33 features and eliminate the other 28 features .I also tried with Logistic picked top 20 features.
          All of my predictors are categorical and my target is also categorical and known(Supervised Machine Learning) ,So, Classification is the best choice.I tried different Classification methods like Logistic, Ridge and Lasso and constructed the confusion matrix and visualised the Roc curve.
          Also, I tried Random Forest, Support Vector Machine classifier, Decision Tree Classifier, KNN(Know your nearest neighbour classifier) , Adaptive boosting .Out of them , Logistic has given 78.8% accuracy with less number of False positives and False negatives.The area under ROC curve is 0.81.
<<<<<<< HEAD
          The detailed analysis can be seen in my github
          <a>https://github.com/Indu4191/Projects/tree/master/Capstone%20Project </a>
=======
          The detailed analysis can be
          <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/Capstone%20Project">seen in my github repo.</a>
>>>>>>> 82e66c4ce0410474de3db80ccd4a544aa9f49a14
        </p>
        <p>
          I have met most of the objectives in learning Machine Learning concepts, being able to apply various models, algorithms, and strategies to achieve relatively good predictions.My best prediction accuracy is 78.8% which seems to good outcome.
        </p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
<div id="webscrape" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Overview</h4>
      </div>
      <div class="modal-body">
        <p> This a project where Web scraping and predictive analysis is involved.The main goal of the project is to get data from any job portal using Web Scraping and Predictive analysis is done on Salary.To figure out the factors influences the Salary, Machine Learning Techniques are used.
<<<<<<< HEAD
            Web Scraping on <a> https://www.seek.com.au/ </a>is performed using scrapy.I have taken for keywords like  Data Analyst, Data Scientist, Business Analyst and Data Engineer. I have considered for Sydney, Melbourne and Brisbane.I made the details as a data frame with their corresponding industry, work type, Company that advertised, Salary, region (like inner suburbs, CBD), Job description in two different columns, page number and URL.
        </p>
        <p>Data Cleaning is performed for Exploratory Data Analysis.I visualised using Python libraries (matplotlib, Seaborn) and with Tableau.I got some interesting findings from Data Visualisation.
           Sydney has more jobs with work type as full time.out of all industries, Salary paid highest to the Information and Technology.you can find many more findings in my Tableau public workbook here
          <a> https://public.tableau.com/views/predictionsonwebscrapedjobs/Story1?:embed=y&:display_count=yes&publish=yes </a>
          <p>After that Feature Engineering is performed.I performed Decision Tree Classifier, Logistic Regression Classifier to investigate the factors affecting salary(high vs low).I got that seniority level with Information and Technology in Sydney is influencing the salary.
            Data modelling of job skills and keywords are investigated that impact salary.keywords like research, design, data, modelling, SQL are listed at the top.From here I concentrated on Data Science Jobs, I got that Science and Technology who has Masters with job location Sydney are paid more.
            The skills and locations which are most common in key industries are Information and Communications, Accounting and Finance.
            I constructed the confusion matrix where I got 71.3% accuracy in predicting salary range with Roc curve of 0.75.The entire analysis can be viewed in my GitHub
            <a> https://github.com/Indu4191/Projects/tree/master/webscraping%20%26%20predictive%20anlysis </a>
          </p>
=======
            Web Scraping on <a target="_blank" href="https://www.seek.com.au/">Seek website</a> is performed using scrapy.I have taken for keywords like  Data Analyst, Data Scientist, Business Analyst and Data Engineer. I have considered for Sydney, Melbourne and Brisbane.I made the details as a data frame with their corresponding industry, work type, Company that advertised, Salary, region (like inner suburbs, CBD), Job description in two different columns, page number and URL.
        </p>
        <p>Data Cleaning is performed for Exploratory Data Analysis.I visualised using Python libraries (matplotlib, Seaborn)
           and with Tableau.I got some interesting findings from Data Visualisation. Sydney has more jobs with work type as
           full time.out of all industries, Salary paid highest to the Information and Technology.you can find many more
           findings in
          <a target="_blank" href="https://public.tableau.com/views/predictionsonwebscrapedjobs/Story1?:embed=y&:display_count=yes&publish=yes ">
            my Tableau public workbook
          </a>
        </p>
        <p>After that Feature Engineering is performed.I performed Decision Tree Classifier, Logistic Regression Classifier to
          investigate the factors affecting salary(high vs low).I got that seniority level with Information and Technology in
          Sydney is influencing the salary. Data modelling of job skills and keywords are investigated that impact salary.
          Keywords like research, design, data, modelling, SQL are listed at the top.From here I concentrated on Data Science Jobs,
          I got that Science and Technology who has Masters with job location Sydney are paid more.
          The skills and locations which are most common in key industries are Information and Communications, Accounting and Finance.
          I constructed the confusion matrix where I got 71.3% accuracy in predicting salary range with Roc curve of 0.75.The entire analysis can be viewed in
          <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/webscraping%20%26%20predictive%20anlysis">my GitHub repo</a>
        </p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
<div id="predictive" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Estimating the value of homes from fixed characteristics.</h4>
      </div>
      <div class="modal-body">
        <p>
          The project’s motto is to,
        </p>
        <ul>
          <li>Develop an algorithm to reliably estimate the value of residential houses based on fixed characteristics.</li>
          <li> Identify characteristics of houses that the company can cost-effectively change/renovate with their construction team.</li>
          <li>Evaluate the mean dollar value of different renovations.</li>
        </ul>
        <p>
          I got the dataset and description text  from the kaggle. When I started exploring my dataset, I observed a lot of variables have null values.
          Some are continuous, others categorical.I wrote a function to fill in both. The categorical ones can be filled and a few of the continuous
           ones can be filled with 0.I dropped some unwanted columns to make my analysis easier. There are 72 selected features!
           That's quite a few. The top variables make sense as far as what is important to estimate the price: living area, cars in
           the garage, neighbourhood, age when sold, fireplaces, etc.
        </p>
        <p>
           These coefficients are a bit hard to interpret:
        </p>
        <ul>
          <li>They are in terms of standard deviations of the predictor.</li>
          <li>The target is in log terms (orders of magnitude) So basically a coefficient is saying "for a 1 standard deviation
            increase in this predictor, there will be an x increase in orders of magnitude of the sale price”.</li>
        </ul>
        <p>
          Now that my model that estimates the price of a house based on its static characteristics. My target is to
        </p>
        <ul>
          <li>How would your company use this second model and its coefficients to determine whether they should buy a property or not? </li>
          <li>Explain how the company can use the two models you have built to determine if they can make money.</li>
          <li>Investigate how much of the variance in price remaining is explained by these features.</li>
          <li>Do you trust your model? Should it be used to evaluate which properties to buy and fix up?</li>
        </ul>
        <p>
          You can view my analysis <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/Analysis%20for%20Real%20Estate">here in my GitHub</a>
        </p>
        <p>
          I got some interesting outcomes, these are the valid features indicating for closure vs. not:
        </p>
        <ul>
          <li>North Ames neighbourhood</li>
          <li>North Ridge neighbourhood</li>
          <li>Single level house</li>
          <li>Brick and stone exterior</li>
          <li>Electrical "mix"</li>
          <li>"Severe" functionality of house (bad)</li>
        </ul>
        <p>
          Features predicting against forclosure:
        </p>
        <ul>
          <li>North ridge heights neighbourhood</li>
          <li>Good quality fireplace</li>
          <li>No fence</li>
          <li>Sold in month 6. Interesting.</li>
          <li>A later year remodelled (more recent)</li>
          <li>A lower sale price.</li>
        </ul>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
<div id="greenness" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Predicting "Greenness" Of Content</h4>
      </div>
      <div class="modal-body">
        <p>
          The mission is to build a classifier which will evaluate a large set of URLs and label them as either evergreen or ephemeral.A high-quality
          prediction of "ephemeral" or "evergreen" would greatly improve a recommendation system.
        </p>
        <p>
          This dataset comes from <a target="_blank" href="https://www.stumbleupon.com/">stumbleupon</a> a web page recommender and was made available
          <a target="_blank" href="https://www.kaggle.com/c/stumbleupon/download/train.tsv">here</a>. Data cleaning is performed on tsv file.Two new columns body,
          title are made from the boilerplate column.The boilerplate column is in JSON dictionary format.  JSON.loads() function is used from the
          JSON module to convert this into a python dictionary.
        </p>
        <p>
          To determine evergreen sites, websites that always relevant like recipes or reviews (as opposed to current events) are taken and stored as a
          binary indicator in the label column.The effect of being a news site on evergreen status is insignificant.More formally, we would accept the
          null hypothesis that news sites and non-news sites have an equal probability of being evergreen.
        </p>
        <p>
           Many of the categories appear to have a significant effect on the likelihood of evergreen status. Note that I have set the reference category
           to be unknown. This is wrapped into the intercept term. These categories must be interpreted as significantly different from unknown or not
        </p>
        <p>Positive predictors of evergreen vs. unknown:</p>
        <ul>
          <li>Business</li>
          <li>Health</li>
          <li>Recreation</li>
        </ul>
        <p>
          Negative predictors of evergreen vs. unknown:
        </p>
        <ul>
          <li>Arts and entertainment</li>
          <li>Computer and the Internet</li>
          <li>Gaming</li>
          <li>Sports</li>
        </ul>
        <p>
           The rest of the categories are not significantly different than the unknown category in their probability of being evergreen or not.
        </p>
        <ul>
          <li>They are in terms of standard deviations of the predictor.</li>
          <li>The target is in log terms (orders of magnitude) So basically a coefficient is saying "for a 1 standard deviation
            increase in this predictor, there will be an x increase in orders of magnitude of the sale price”.</li>
        </ul>
        <p>
          Now that my model that estimates the price of a house based on its static characteristics. My target is to
        </p>
        <p>
          Once it's modelled well (convert the image ratio to percentiles and include a quadratic term) we can see these significant effects:
        </p>
        <ul>
          <li>There is a positive effect of the image ratio percentile score (its rank across image_ratios)</li>
          <li>There is a negative quadratic effect of image ratio. That is to say, at a certain point, the squared term of image_ratio_pctl overtakes the
            linear term. The highest probability of evergreen sites have image ratios in the median range.</li>
        </ul>
        <p>
          Here are all significant effects on our predictors here.
          Must interpret them as odds ratios.:
        </p>
        <ul>
          <li>For a 1 percentile increase in image_ratio, there is a ~1.03x increase in the odds of evergreen</li>
          <li>For a 1 unit increase in image_ratio_pctl**2, there is a ~0.999x decrease in the odds of evergreen</li>
          <li>For a 1 percentile increase in html_ratio, there is a ~0.992x decrease in the odds of evergreen</li>
          <li>For a 1-word increase in the length of the title, there is a ~0.956x decrease in the odds of evergreen</li>
        </ul>
        <p>
          You can view my analysis <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/evergreen%20sites">here in my GitHub</a>
        </p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
<div id="music" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">what common themes are there, is there a trend among artists (type of music)?</h4>
      </div>
      <div class="modal-body">
        <ul>
          <li>Time it takes a song to get to the top.</li>
          <li>Converting song time to an actual time (from a string)</li>
          <li>Weekly Average Rating</li>
          <li>How many weeks a song was number 1</li>
          <li>Get the correct genre for each artist</li>
          <li>Word that appears most often in song Names</li>
          <li>Entry level rating of Genre</li>
          <li>Time to peak grouped by Genre</li>
          <li>Visualise the lifecycle of a song (average)</li>
        </ul>
        <p>
          You can
          <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/Music%20Blogging">view complete analysis in my github repo.</a>
        </p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
<div id="walmart" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Trend Analysis using ARIMA</h4>
      </div>
      <div class="modal-body">
        <p>
          Analysing weekly Walmart sales data over a two year period from 2010 to 2012.The most common application for AR, ARMA, and ARIMA models is inventory plann
          So, the main focus is to
          Record any observed trends in the data,
          Produce a trained model to predict future sales numbers
          Assemble the findings in a report
        </p>
        <p>
          You can
          <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/ARIMA%20lab">view complete analysis in my github repo.</a>
        </p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
<div id="sentiment" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Sentiment Analysis Natural Language Processing</h4>
      </div>
      <div class="modal-body">
        <p>
          A predefined dictionary of positive and negative valences for words is used to find which words are most likely to appear in positive or
          negative reviews by using the rotten vs. fresh binary label.
        </p>
        <p>
          You can
          <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/Sentiment%20Analysis">view complete analysis in my github repo.</a>
        </p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
<div id="churn" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">KNN classification - imputation: Cellphone churn data</h4>
      </div>
      <div class="modal-body">
        <p>
          You can
          <a target="_blank" href="https://github.com/Indu4191/Projects/tree/master/Analysis%20on%20Churn%20data">view complete analysis in my github repo.</a>
        </p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-default" data-dismiss="modal">Close</button>
      </div>
    </div>
  </div>
</div>
>>>>>>> 82e66c4ce0410474de3db80ccd4a544aa9f49a14
<script type="text/javascript" src="js/jquery.1.11.1.js"></script>
<script type="text/javascript" src="js/bootstrap.js"></script>
<script type="text/javascript" src="js/SmoothScroll.js"></script>
<script type="text/javascript" src="js/nivo-lightbox.js"></script>
<script type="text/javascript" src="js/jquery.isotope.js"></script>
<script type="text/javascript" src="js/jqBootstrapValidation.js"></script>
<script type="text/javascript" src="js/main.js"></script>
</body>
</html>
